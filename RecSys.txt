


 >>> Contemporary neural nets for RecSys is possible but not without challenges! <<<



6. AUTORECS - AUTOENCODERS FOR RECOMMENDATIONS
----------------------------------------------


[Figure]

Note: In paper they trained once per item  - Feeding in ratings from each user for that item in input layer.
      Sigmoid activation functioin was used in output layer


	- Slightly better results than RBM
	- Here, compared to RBM, we have different sets of weights as well(not just different sets of biases)
	- Easier to implement in modern frameworks such as TF or Keras



CHALLENGE: SPARSICITY
---------


IN PAPER: "We only consider contribution of observed ratings"
	   
	   i.e. They were careful to process each path through this neural net individually only propogating information
	   from ratings that actually exist in training data and ignoring contribution input nodes corresponding
	   to missing data.

	=> It is hard to implementin TF. Even if it has sparse tensors, there is no simple way to restrict chain
	   of matrix multiplications and additions needed to implement in neural net to just input nodes with 
	   actual data in them.
	   Implementation in TF or Keras ignores that problem and models missing ratings as zeros. This gives
	   decent results but has a fundamental problem in it!
		
	This architecture - "AUTOENCODERS"
 
- Encoding Inputs: Building up 
